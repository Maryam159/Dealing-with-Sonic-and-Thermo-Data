{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to deal with Sonic Data containing heavy files?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st Stepin case we have Sonic Data(Giving txt Files Column Names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names assigned to TOA5_4174_Sonic_I1_09_2023_02_12_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_10_2023_02_13_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_11_2023_02_14_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_14_2023_02_15_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_15_2023_02_16_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_16_2023_02_17_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_17_2023_02_18_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_18_2023_02_19_0000_despik.txt\n",
      "Column names assigned to TOA5_4174_Sonic_I1_19_2023_02_20_0000_despik.txt\n",
      "Column names assigned to all files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory containing the files\n",
    "files_directory = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Input'\n",
    "\n",
    "# Define column names\n",
    "column_names = ['Year', 'Month', 'Day', 'Hour', 'Minute',\n",
    "                'Second.Millisec', 'u [m/s]', 'v [m/s]', 'w [m/s]', 'T [°C]',\n",
    "                'U [m/s]', 'WD [°]', 'u_{met} [m/s]', ' v_{met} [m/s]', 'Empty']\n",
    "\n",
    "# Iterate over the files\n",
    "for file_name in os.listdir(files_directory):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(files_directory, file_name)\n",
    "\n",
    "        # Read the file into a DataFrame without a header\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', header=None)\n",
    "\n",
    "        # Assign the column names to the DataFrame\n",
    "        df.columns = column_names\n",
    "\n",
    "        # Write the DataFrame back to the file, replacing the original data\n",
    "        df.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"Column names assigned to {file_name}\")\n",
    "\n",
    "print(\"Column names assigned to all files.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Step (Converting Miliseconds Data into seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second.Millisec', 'u [m/s]', 'v [m/s]', 'w [m/s]', 'T [Â°C]', 'U [m/s]', 'WD [Â°]', 'u_{met} [m/s]', ' v_{met} [m/s]', 'Empty']\n",
      "Filtering completed! The output TXT file is located at B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/TOA5_4175_Sonic_I2_11_2023_02_13_0000_despik_Seconds.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your TXT file\n",
    "txt_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Input/TOA5_4175_Sonic_I2_11_2023_02_13_0000_despik.txt'\n",
    "               #  B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Input/TOA5_6551_Sonic_BP3_06_2023_02_12_0000_despik.txt\n",
    "\n",
    "# Open the TXT file\n",
    "with open(txt_file_path, 'r') as txt_file:\n",
    "    lines = txt_file.readlines()\n",
    "\n",
    "    # Read the header line\n",
    "    header = lines[0].strip().split('\\t')\n",
    "    print(header)  # Print the header line\n",
    "\n",
    "    # Identify the index of the \"Second.Millisec\" column\n",
    "    second_millisec_index = header.index(\"Second.Millisec\")\n",
    "\n",
    "    # Create a list to store the filtered lines\n",
    "    filtered_lines = []\n",
    "\n",
    "    # Process each line in the TXT file\n",
    "    for line in lines[1:]:\n",
    "        row = line.strip().split('\\t')\n",
    "        second_millisec = float(row[second_millisec_index])\n",
    "        if second_millisec.is_integer():\n",
    "            # Add the line to the filtered lines list\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "# Create a new TXT file for the filtered linesTOA5_4175_Sonic_I2_10_2023_02_12_0000_despik_Seconds\n",
    "output_file_path = txt_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/TOA5_4175_Sonic_I2_11_2023_02_13_0000_despik_Seconds.txt'\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write('\\t'.join(header) + '\\n')  # Write the header line\n",
    "    output_file.writelines(filtered_lines)  # Write the filtered lines\n",
    "\n",
    "print(f\"Filtering completed! The output TXT file is located at {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd Step (Converting Seconds Data into Minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging completed! The output CSV file is located at B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/TOA5_4175_Sonic_I2_12_2023_02_14_0000_despik_Minutes.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/TOA5_4175_Sonic_I2_12_2023_02_14_0000_despik_Seconds.txt'\n",
    "encoding = 'utf-8'  # Try different encodings like 'latin-1' or 'cp1252'\n",
    "\n",
    "# Read the file using specified encoding and handle any parsing errors\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path, encoding=encoding, delimiter='\\t')\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error occurred while parsing the file: {e}\")\n",
    "    # Add additional error handling or preprocessing steps if necessary\n",
    "    # ...\n",
    "    # Stop further execution or return an error message\n",
    "\n",
    "# Continue with your remaining code (e.g., averaging, saving to CSV)\n",
    "averaged_df = df.groupby(df.index // 60).mean()\n",
    "output_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/TOA5_4175_Sonic_I2_12_2023_02_14_0000_despik_Minutes.txt'\n",
    "averaged_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Averaging completed! The output CSV file is located at {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th Step (Code to combine multiple excel files data into one file (This code also keeps the sequence of time). In this code I combined the data of 9 days in 1 file in a sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combination completed! The output CSV file is located at B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/IrnerioRooftop_Sonic_combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory path for the files\n",
    "directory = \"B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/Code Automation test\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over the file list\n",
    "for file_name in file_list:\n",
    "    # Construct the full file path by joining the directory path and the filename\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "\n",
    "    # Read the data from each file\n",
    "    day_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Concatenate the data frames\n",
    "    combined_data = pd.concat([combined_data, day_data], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a new file\n",
    "output_file_path = \"B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/IrnerioRooftop_Sonic_combined_data.csv\"\n",
    "combined_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data combination completed! The output CSV file is located at {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How  to  handle  Thermo  Data  Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st Stepin case we have Thermo Data Data(Giving txt Files Column Names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory containing the files\n",
    "files_directory = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Input'\n",
    "\n",
    "# Define column names\n",
    "column_names = ['Year', 'Month', 'Day', 'Hour', 'Minute',\n",
    "                'Second', 'T [°C]', 'RH [%]', 'P [hPa]','Empty']\n",
    "\n",
    "# Iterate over the files\n",
    "for file_name in os.listdir(files_directory):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(files_directory, file_name)\n",
    "\n",
    "        # Read the file into a DataFrame without a header\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', header=None)\n",
    "\n",
    "        # Assign the column names to the DataFrame\n",
    "        df.columns = column_names\n",
    "\n",
    "        # Write the DataFrame back to the file, replacing the original data\n",
    "        df.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"Column names assigned to {file_name}\")\n",
    "\n",
    "print(\"Column names assigned to all files.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 (Converting Seconds Data into Minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Input/Thermo_IrnerioRooftop_2023_2_15_raw.txt'\n",
    "encoding = 'utf-8'  # Try different encodings like 'latin-1' or 'cp1252'\n",
    "\n",
    "# Read the file using specified encoding and handle any parsing errors\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path, encoding=encoding, delimiter='\\t')\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error occurred while parsing the file: {e}\")\n",
    "    # Add additional error handling or preprocessing steps if necessary\n",
    "    # ...\n",
    "    # Stop further execution or return an error message\n",
    "\n",
    "# Continue with your remaining code (e.g., averaging, saving to CSV)\n",
    "averaged_df = df.groupby(df.index // 60).mean()\n",
    "output_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/Thermo_IrnerioRooftop_2023_2_15_raw_Minutes.txt'\n",
    "averaged_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Averaging completed! The output CSV file is located at {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data for 16th Feb was not changing into minutes from the above code so I have to make another code for this 16th February only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Input/Thermo_IrnerioRooftop_2023_2_16_raw.txt'\n",
    "encoding = 'utf-8'  # Try different encodings like 'latin-1' or 'cp1252'\n",
    "\n",
    "# Read the file using specified encoding and handle any parsing errors\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path, encoding=encoding, delimiter='\\t')\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error occurred while parsing the file: {e}\")\n",
    "    # Add additional error handling or preprocessing steps if necessary\n",
    "    # ...\n",
    "    # Stop further execution or return an error message\n",
    "\n",
    "# Continue with your remaining code (e.g., averaging, saving to CSV)\n",
    "averaged_df = df.groupby(df.index // 60).mean()\n",
    "output_file_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/Thermo_IrnerioRooftop_2023_2_16_raw_Minutes.txt'\n",
    "averaged_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Averaging completed! The output CSV file is located at {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th Step (Code to combine multiple excel files data into one file (This code also keeps the sequence of time). In this code I combined the data of 9 days in 1 file in a sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combination completed! The output CSV file is located at B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/IrnerioVan_Thermo_combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory path for the files\n",
    "directory = \"B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/Code Automation test\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over the file list\n",
    "for file_name in file_list:\n",
    "    # Construct the full file path by joining the directory path and the filename\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "\n",
    "    # Read the data from each file\n",
    "    day_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Concatenate the data frames\n",
    "    combined_data = pd.concat([combined_data, day_data], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a new file\n",
    "output_file_path = \"B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/IrnerioVan_Thermo_combined_data.csv\"\n",
    "combined_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data combination completed! The output CSV file is located at {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to change all files in the folder at once (Mili Seconds to Seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the path to the input folder containing the TXT files\n",
    "input_folder_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Input/'\n",
    "\n",
    "# Specify the path to the output folder for the filtered TXT files\n",
    "output_folder_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/'\n",
    "\n",
    "# Get a list of all files in the input folder\n",
    "input_files = os.listdir(input_folder_path)\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    # Construct the input file path\n",
    "    input_file_path = os.path.join(input_folder_path, input_file)\n",
    "\n",
    "    # Open the input TXT file\n",
    "    with open(input_file_path, 'r') as txt_file:\n",
    "        lines = txt_file.readlines()\n",
    "\n",
    "        # Read the header line\n",
    "        header = lines[0].strip().split('\\t')\n",
    "\n",
    "        # Identify the index of the \"Second.Millisec\" column\n",
    "        second_millisec_index = header.index(\"Second.Millisec\")\n",
    "\n",
    "        # Create a list to store the filtered lines\n",
    "        filtered_lines = []\n",
    "\n",
    "        # Process each line in the TXT file\n",
    "        for line in lines[1:]:\n",
    "            row = line.strip().split('\\t')\n",
    "            second_millisec = float(row[second_millisec_index])\n",
    "            if second_millisec.is_integer():\n",
    "                # Add the line to the filtered lines list\n",
    "                filtered_lines.append(line)\n",
    "\n",
    "    # Construct the output file path with a modified name\n",
    "    output_file_name = os.path.splitext(input_file)[0] + '_Seconds.txt'\n",
    "    output_file_path = os.path.join(output_folder_path, output_file_name)\n",
    "\n",
    "    # Create a new TXT file for the filtered lines\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        output_file.write('\\t'.join(header) + '\\n')  # Write the header line\n",
    "        output_file.writelines(filtered_lines)  # Write the filtered lines\n",
    "\n",
    "    print(f\"Filtering completed for {input_file}! The output TXT file is located at {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to change all files in the folder at once (Seconds to Minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the input folder containing the TXT files\n",
    "input_folder_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/'\n",
    "\n",
    "# Specify the path to the output folder for the averaged TXT files\n",
    "output_folder_path = 'B:/Python Self Learning/New folder/Meteo Data/MeteoData/MeteoData/txt to csv conversion/Output/'\n",
    "\n",
    "# Specify the encoding for your TXT files\n",
    "encoding = 'utf-8'  # Update with the appropriate encoding if needed\n",
    "\n",
    "# Get a list of all files in the input folder\n",
    "input_files = os.listdir(input_folder_path)\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    # Construct the input file path\n",
    "    input_file_path = os.path.join(input_folder_path, input_file)\n",
    "\n",
    "    # Read the file using specified encoding and handle any parsing errors\n",
    "    try:\n",
    "        df = pd.read_csv(input_file_path, encoding=encoding, delimiter='\\t')\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error occurred while parsing the file: {e}\")\n",
    "        continue  # Continue with the next file\n",
    "\n",
    "    # Perform averaging on the data\n",
    "    averaged_df = df.groupby(df.index // 60).mean()\n",
    "\n",
    "    # Construct the output file path with a modified name\n",
    "    output_file_name = os.path.splitext(input_file)[0] + '_Minutes.txt'\n",
    "    output_file_path = os.path.join(output_folder_path, output_file_name)\n",
    "\n",
    "    # Save the averaged data to the output file\n",
    "    averaged_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Averaging completed for {input_file}! The output TXT file is located at {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
